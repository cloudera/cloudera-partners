= Cloudera Kubernetes Operators Installation Guide
v0.1, 2025-04-10: Draft
:description: Installation instructions for Cloudera Kubernetes Operators
:toc: left
:toclevels: 2
:sectnums:
:source-highlighter: rouge
:icons: font
:imagesdir: ./images
:hide-uri-scheme:
:homepage: https://github.com/cloudera/cloudera-partners

[WARNING]
====
📝 **DRAFT** — This document is WIP and Not Final.
====

== Overview

This document walks through the installation and setup of Cloudera's Kubernetes Operators on a local instance for development and testing.
The canonical documentation is https://docs.cloudera.com/?tab=kubernetes-operators[here]

== Minimum Pre-Requisites

. Ubuntu version 24 and above 
.. Recommended Ubuntu 24.04.2 LTS
. 16 GB RAM
. 100GB HD

. Cloudera license
.. Request a https://github.com/cloudera/cloudera-partners/tree/main/PartnerResources#partner-developer-license-program[Free Partner Developer License]

== Installation

. Get the latest updates
+
[source, bash]
----
sudo apt-get update
----

. Install docker
.. Remove old docker instance
+
[source, bash]
----
sudo apt remove docker docker-engine docker.io containerd runc
----

.. Install dependencies
+
[source, bash]
----
sudo apt install ca-certificates curl gnupg lsb-release
----

.. Add Docker GPG Key & Repository
+
[source, bash]
----
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
----

.. Add Docker Repo
+
[source, bash]
----
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
----

.. Install 
+
[source, bash]
----
sudo apt-get update
yes | sudo apt-get install docker-ce docker-ce-cli
----

.. Manage Docker as a Non-Root User
+
[source, bash]
----
sudo usermod -aG docker $USER
----

... Refresh group changes
+
[source, bash]
----
newgrp docker
----

.. Enable Docker to start on Boot
+
[source, bash]
----
sudo systemctl enable docker
sudo systemctl start docker
----

. Install latest version of kubectl
+
[source, bash]
----
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
----

.. Make it installable and move to PATH
+
[source, bash]
----
chmod +x kubectl
sudo mv kubectl /usr/local/bin/
----

. Install k9s utility for management
+
[source, bash]
----
curl -LO https://github.com/derailed/k9s/releases/latest/download/k9s_Linux_amd64.deb
sudo dpkg -i k9s_Linux_amd64.deb
rm k9s_Linux_amd64.deb
----

. Install helm
+
[source, bash]
----
curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
----

. Install minikube
+
[source, bash]
----
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
rm minikube-linux-amd64  # Cleanup
----

. Deploy OpenLDAP in Kubernetes
+
[source, bash]
----
helm repo add helm-openldap https://jp-gouin.github.io/helm-openldap/
helm install openldap helm-openldap/openldap-stack-ha --create-namespace --namespace openldap -f openldap-values.yaml
----

. Install cert-manager (for automatic SSL/TLS certificate management in Kubernetes)
+
[source, bash]
----
helm repo add jetstack https://charts.jetstack.io --force-update
helm install \
  cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --set crds.enabled=true
----

. Deploy ClusterIssuer
+
[source, bash]
----
cat <<EOF > clusterissuer.yaml
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: self-signed-ca-issuer
spec:
  selfSigned: {}
EOF
kubectl apply -f clusterissuer.yaml
----

. Deploy CFM Operator
.. Create namespace
+
[source, bash]
----
kubectl create namespace cfm-operator-system
----

.. Create Docker registry secret
+
[source, bash]
----
kubectl create secret docker-registry docker-pull-secret \
  --namespace cfm-operator-system \
  --docker-server container.repository.cloudera.com \
  --docker-username ${Cloudera_username} \
  --docker-password ${Cloudera_password}
----

.. Create license secret
+
[source, bash]
----
kubectl create secret generic cfm-operator-license \
  --from-file=license.txt=./cloudera_license.txt \
  -n cfm-operator-system
# where cloudera_license.txt is the Cloudera license file.
----

.. Download and extract the CFM Operator package
+
[source, bash]
----
curl -u "${Cloudera_username}:${Cloudera_password}" \
  -O https://archive.cloudera.com/p/cfm-operator/cfm-operator-${cfm_operator_version}.tgz

tar -xvzf cfm-operator-${cfm_operator_version}.tgz
----

.. Install the CFM Operator using Helm
+
[source, bash]
----
helm install cfm-operator ./cfm-operator \
  --create-namespace \
  --namespace cfm-operator-system \
  --set installCRDs=true \
  --set image.repository=container.repository.cloudera.com/cloudera/cfm-operator \
  --set image.tag=${cfm_operator_version} \
  --set licenseSecret=cfm-operator-license
----

. Deploy NiFi
.. Create namespace
+
[source, bash]
----
kubectl create namespace demo-nifi
----

.. Create Docker registry secret for NiFi
+
[source, bash]
----
kubectl create secret docker-registry docker-pull-secret \
  --namespace demo-nifi \
  --docker-server container.repository.cloudera.com \
  --docker-username ${Cloudera_username} \
  --docker-password ${Cloudera_password}
----

.. Create OpenLDAP secret (if using LDAP)
+
[source, bash]
----
kubectl create secret generic openldap-creds \
  --from-literal=managerPassword=${ldapadmin_password} \
  -n demo-nifi
----

.. Apply NiFi configuration overrides
+
[source, bash]
----
# Make sure you're in the same directory where nifi_overrides.yaml exists.
kubectl apply -f nifi_overrides.yaml -n demo-nifi
----

.. Expose the NiFi UI using NodePort and access via SSH tunneling(e.g When running minikube in an ec2 instance)

... Change NiFi service type to NodePort
+
[source, bash]
----
kubectl -n demo-nifi patch svc demonifi-web \
  -p '{"spec": {"type": "NodePort"}}'
----

... Get the NodePort value
+
[source, bash]
----
kubectl get svc demonifi-web -n demo-nifi -o jsonpath='{.spec.ports[*].nodePort}'
----

... SSH tunneling example
+
[source, bash]
----
ssh -L 8443:192.168.49.2:32156 ubuntu@13.215.183.137
----

... SSH tunneling with PEM key
+
[source, bash]
----
ssh -f -N -i <PEM_FILE_LOCATION> \
  -L 8443:192.168.49.2:<NodePort> ubuntu@<ec2PublicIp>
----

. Deploy NiFi Registry
.. Create namespace
+
[source,bash]
----
kubectl create namespace demo-nifi-registry
----

.. Create Docker registry secret for NiFi Registry
+
[source,bash]
----
kubectl create secret docker-registry docker-pull-secret \
  --namespace demo-nifi-registry \
  --docker-server container.repository.cloudera.com \
  --docker-username ${Cloudera_username} \
  --docker-password ${Cloudera_password}
----

.. Create OpenLDAP secret (if using LDAP)
+
[source,bash]
----
kubectl create secret generic openldap-creds \
  --from-literal=managerPassword=${managerPassword} \
  -n demo-nifi-registry
----

.. Apply NiFi Registry configuration
+
[source,bash]
----
# Make sure you're in the same directory where nifiregistry.yaml exists.
kubectl apply -f nifiregistry.yaml --namespace demo-nifi-registry
----

.. Expose the NiFi Registry UI using NodePort and access via SSH tunneling (e.g. when running minikube on an EC2 instance)

... Change NiFi Registry service type to NodePort
+
[source,bash]
----
kubectl -n demo-nifi-registry patch svc demonifiregistry-web \
  -p '{"spec": {"type": "NodePort"}}'
----

... Get the NodePort value
+
[source,bash]
----
kubectl get svc demonifiregistry-web -n demo-nifi-registry -o jsonpath='{.spec.ports[*].nodePort}'
----

... SSH tunneling with PEM key
+
[source,bash]
----
ssh -f -N -i <PEM_FILE_LOCATION> \
  -L 18443:192.168.49.2:<NodePort> ubuntu@<ec2PublicIp>
----

. Deploy CSA operator
.. Create namespace
+ 
[source,bash]
----
kubectl create namespace csa-operator-system
----

.. Create Docker registry secret for CSA
+ 
[source,bash]
----
kubectl create secret docker-registry docker-pull-secret \
  --namespace csa-operator-system \
  --docker-server container.repository.cloudera.com \
  --docker-username ${Cloudera_username} \
  --docker-password ${Cloudera_password}
----

.. Set environment variables for Cloudera username and password
+ 
[source,bash]
----
export Cloudera_username="${Cloudera_username}"
export Cloudera_password="${Cloudera_password}"
----

.. Log in to Cloudera registry using Helm
+ 
[source,bash]
----
echo "${Cloudera_password}" | helm registry login container.repository.cloudera.com \
    --username "$Cloudera_username" \
    --password-stdin
----

.. Install CSA operator using Helm
+ 
[source,bash]
----
helm install csa-operator --namespace csa-operator-system \
    --set 'flink-kubernetes-operator.imagePullSecrets[0].name=docker-pull-secret' \
    --set 'ssb.sse.image.imagePullSecrets[0].name=docker-pull-secret' \
    --set 'ssb.sqlRunner.image.imagePullSecrets[0].name=docker-pull-secret' \
    --set-file flink-kubernetes-operator.clouderaLicense.fileContent=./cloudera_license.txt \
oci://container.repository.cloudera.com/cloudera-helm/csa-operator/csa-operator --version ${csa_operator_version}
----

.. Verify CSA operator installation
+ 
[source,bash]
----
kubectl get pods -n csa-operator-system
----

. Deploy Flink
.. Deploy Flink application using session Cluster deployments
+ 
[source,bash]
----
kubectl -n csa-operator-system apply -f flink-deployment.yaml
----

.. Below is how you can deploy Flink job [Optional]
+ 
[source,bash]
----
cat <<EOF > flink_job_session.yaml
apiVersion: flink.apache.org/v1beta1
kind: FlinkSessionJob
metadata:
  name: basic-session-job-example
spec:
  deploymentName: <FLINK_DEMPLOYMENT_NAME>
  job:
    jarURI: https://repo1.maven.org/maven2/org/apache/flink/flink-examples-streaming_2.12/1.16.1/flink-examples-streaming_2.12-1.16.1-TopSpeedWindowing.jar
    parallelism: 4
    upgradeMode: stateless
EOF
#For deploymentName: please use the name you chose for your flink application deployment in the previous step (e.g., deploymentName: demo-flink)

kubectl apply -f flink_job_session.yaml
----

.. Access Flink UI when running on local laptop
+ 
[source,bash]
----
kubectl -n csa-operator-system port-forward service/demo-flink-rest 8081:8081
----

.. Expose the Flink UI using NodePort and access via SSH tunneling (e.g. when running minikube on an EC2 instance)
... Patch cluster IP service to NodePort
+ 
[source,bash]
----
kubectl -n csa-operator-system patch svc demo-flink-rest -p '{"spec": {"type": "NodePort"}}'
----

... Get the NodePort value
+ 
[source,bash]
----
kubectl get svc <service-name> -n <namespace> -o jsonpath='{.spec.ports[*].nodePort}'
----

... SSH tunneling for local port forward
+ 
[source,bash]
----
ssh -f -N -i <PEM_FILE_LOCATION> -L 8081:192.168.49.2:<NodePort> ubuntu@<ec2PublicIp>
----

.. Expose the SSB UI using NodePort and access via SSH tunneling(e.g When running minikube in an ec2 instance)
... Change SSB service type to NodePort
+ 
[source,bash]
----
kubectl -n csa-operator-system patch svc ssb-sse -p '{"spec": {"type": "NodePort"}}'
----

... Get the NodePort value for SSB UI
+ 
[source,bash]
----
kubectl get svc <service-name> -n <namespace> -o jsonpath='{.spec.ports[*].nodePort}'
----

... SSH tunneling for local port forward
+ 
[source,bash]
----
ssh -f -N -i <PEM_FILE_LOCATION> -L 18121:192.168.49.2:<NodePort> ubuntu@<ec2PublicIp>
----

. Deploy CSM Operator
.. Create namespace for CSM Operator
+ 
[source,bash]
----
kubectl create namespace csm-operator-system
----

.. Create Docker registry secret for CSM Operator
+ 
[source,bash]
----
kubectl create secret docker-registry docker-pull-secret \
  --namespace csm-operator-system \
  --docker-server container.repository.cloudera.com \
  --docker-username ${Cloudera_username} \
  --docker-password ${Cloudera_password}
----

.. Set environment variables for Cloudera username and password
+ 
[source,bash]
----
export Cloudera_username="${Cloudera_username}"
export Cloudera_password="${Cloudera_password}"
----

.. Log in to Cloudera registry using Helm
+ 
[source,bash]
----
echo "${Cloudera_password}" | helm registry login container.repository.cloudera.com \
    --username "$Cloudera_username" \
    --password-stdin
----

.. Install Strimzi Kafka Operator using Helm
+ 
[source,bash]
----
helm install strimzi-cluster-operator \
  --namespace csm-operator-system \
  --set 'image.imagePullSecrets[0].name=docker-pull-secret' \
  --set-file clouderaLicense.fileContent=./cloudera_license.txt \
  --set watchAnyNamespace=true \
  oci://container.repository.cloudera.com/cloudera-helm/csm-operator/strimzi-kafka-operator \
  --version ${strimzi-kafka-operator}
----

.. Verify CSM Operator installation
+ 
[source,bash]
----
kubectl get deployments --namespace csm-operator-system
kubectl get pods --namespace csm-operator-system
----

. Deploy Kafka
.. Create namespace for Kafka
+ 
[source,bash]
----
kubectl create namespace cloudera-kafka-demo
----

.. Create Docker registry secret for Kafka
+ 
[source,bash]
----
kubectl create secret docker-registry docker-pull-secret \
  --namespace cloudera-kafka-demo \
  --docker-server container.repository.cloudera.com \
  --docker-username ${Cloudera_username} \
  --docker-password ${Cloudera_password}
----

.. Apply Kafka configurations
+ 
[source,bash]
----
# Make sure all the values.yaml exist in the same directory.
kubectl apply --filename kafka.yaml,nodepool-broker.yaml,nodepool-controller.yaml -n cloudera-kafka-demo
----

. Validating a Kafka cluster
.. Create topic using Kafka Admin
+ 
[source,bash]
----
IMAGE=$(kubectl get pod kafka-cluster-broker-0 --namespace cloudera-kafka-demo --output jsonpath='{.spec.containers[0].image}')
kubectl run kafka-admin -it \
  --namespace cloudera-kafka-demo \
  --image=$IMAGE \
  --rm=true \
  --restart=Never \
  --command -- /opt/kafka/bin/kafka-topics.sh \
    --bootstrap-server kafka-cluster-kafka-bootstrap:9092 \
    --create \
    --topic my-topic
----

.. Produce message to the Kafka topic using Kafka console producer
+ 
[source,bash]
----
kubectl run kafka-producer -it \
  --namespace cloudera-kafka-demo \
  --image=$IMAGE \
  --rm=true \
  --restart=Never \
  --command -- /opt/kafka/bin/kafka-console-producer.sh \
    --bootstrap-server kafka-cluster-kafka-bootstrap:9092 \
    --topic my-topic
----

.. Consume messages from Kafka topic using Kafka console consumer
+ 
[source,bash]
----
kubectl run kafka-consumer -it \
  --namespace cloudera-kafka-demo \
  --image=$IMAGE \
  --rm=true \
  --restart=Never \
  --command -- /opt/kafka/bin/kafka-console-consumer.sh \
    --bootstrap-server kafka-cluster-kafka-bootstrap:9092 \
    --topic my-topic \
    --from-beginning
----





= CDP Private Cloud Data Engineering (CDE)

https://docs.cloudera.com/data-engineering/1.5.4/enable-data-engineering/topics/cde-private-cloud-add-cde-service.html

== CDP Base Cluster Requirements
The Cloudera Data Engineering (CDE) service requires proper configuration of the Ozone service in the Base cluster. Ensure that Ozone is running properly; otherwise, you will encounter issues while enabling CDE.

== Enabling CDE Service
From the CDP console page, click on *Data Engineering*.

This will open the CDE home page. Since this will be the first time you are opening CDE, you will not see any virtual clusters. Click on *Administration* in the left pane.

Click on the *+* icon as shown below, which will allow you to enable the CDE service, after which you can create Virtual Clusters.

On the *Enable a Service* page, enter the values as shown below and then click on *Enable*.

_Note_: The CPU and memory configurations chosen here are minimum values. You can choose to increase them.

This process will take approximately 30 minutes, after which you will be able to see a CDE service on the CDE home page.

(Default *CDE* is the name given as an example. You will see it as per the value entered in the previous step.)

The CDE Home page displays the status of the CDE service initialization. You can view logs for the service by clicking on the service vertical ellipsis (three dots) menu and selecting *View Logs*.

https://docs.cloudera.com/management-console/1.5.4/private-cloud-environments/topics/mc-private-cloud-environment-register-ui.html

If you are unable to see the service, the default virtual cluster might not have been created properly. In this case, click on the *View Services* button, and then you will be able to see the CDE service enabled.

== Create Virtual Cluster
When you enable the CDE service, by default, a new Virtual Cluster with Spark 2.4 will be created. If you have not enabled this option earlier, you need to create a Virtual Cluster again.

On the CDE Home page, click on the *+* icon next to *Virtual Clusters* as shown below.

On the *Create a Virtual Cluster* page, enter the following values and click on *Create*.

* *Cluster Name*: Cluster Name should adhere to the following conditions:
  - Begin with a letter
  - Be between 3 and 30 characters (inclusive)
  - Contain only alphanumeric characters and hyphens
* *Service*: Select the CDE service created earlier.
* *Spark Version*: Select the Spark version as per your requirement. If you need both Spark 2.4 and Spark 3.7, you can create two virtual clusters provided you have sufficient resources.

This process will take approximately 20 minutes. You can check the logs of the cluster creation by clicking on the pencil icon and selecting the *Logs* section on the cluster page as shown below.

== Initializing Virtual Cluster
Every time a new Virtual Cluster is created, there are a few manual steps that must be performed.

Log in to the ECS master and run the next set of commands as per the instructions.

[source,shell]
----
[root@pvcecs-master ~]# mkdir -p /tmp/cde-latest && cd /tmp/cde-latest
[root@pvcecs-master ~]# wget https://docs.cloudera.com/data-engineering/1.5.4/cdp-cde-utils.sh
[root@pvcecs-master ~]# chmod +x /tmp/cde-latest/cdp-cde-utils.sh
----

Identify the virtual cluster endpoint:

On the CDE homepage, select the CDE service in which the virtual cluster is created. Click on the pencil icon on the virtual cluster to be configured.

Click *JOBS API URL* to copy the URL to your clipboard.

Example URL:
http://dfdj6kgx.cde-2cdxw5x5.ecs-demo.example.com/dex/api/v1

From this, the endpoint will be:
dfdj6kgx.cde-2cdxw5x5.ecs-demo.example.com

Run the following command:

[source,shell]
----
[root@pvcecs-master ~]# ./cdp-cde-utils.sh init-virtual-cluster -h <endpoint_host> -a
----

For example:

[source,shell]
----
[root@pvcecs-master ~]# ./cdp-cde-utils.sh init-virtual-cluster -h dfdj6kgx.cde-2cdxw5x5.ecs-demo.example.com -a
----

These steps must be performed for each virtual cluster created.

== Configuring LDAP Users on CDE
This step is required to submit jobs to CDE from LDAP users.

Log in to the ECS master host and navigate to the directory `/tmp/cde-latest`.

[source,shell]
----
[root@pvcecs-master ~]# cd /tmp/cde-latest
[root@pvcecs-master ~]# dnf install krb5-workstation krb5-libs -y
----

Create a principal file:

[source,shell]
----
[root@pvcecs-master ~]# cat>> admin.principal
cdpuser@CLDRSETUP.LOCAL
----

Generate a keytab:

[source,shell]
----
[root@pvcecs-master ~]# sudo ktutil
ktutil:  addent -password -p admin@CLDRSETUP.LOCAL -k 1 -e aes256-cts
Password for admin@CLDRSETUP.LOCAL:
ktutil:  addent -password -p admin@CLDRSETUP.LOCAL -k 2 -e aes128-cts
Password for admin@CLDRSETUP.LOCAL:
ktutil:  wkt admin.keytab
ktutil:  q
----

Validate keytab:

[source,shell]
----
[root@pvcecs-master ~]# klist -ekt admin.keytab
[root@pvcecs-master ~]# kinit -kt admin.keytab admin@CLDRSETUP.LOCAL
[root@pvcecs-master ~]# kdestroy
----

Use the `cdp-cde-utils.sh` script to copy the user keytab to the virtual cluster hosts:

[source,shell]
----
[root@pvcecs-master ~]# ./cdp-cde-utils.sh init-user-in-virtual-cluster -h <endpoint_host> -u <user> -p <principal_file> -k <keytab_file>
----

Example:

[source,shell]
----
[root@pvcecs-master ~]# ./cdp-cde-utils.sh init-user-in-virtual-cluster -h dfdj6kgx.cde-2cdxw5x5.ecs-demo.example.com -u cdpuser -p cdpuser.principal -k cdpuser.keytab
----

Repeat these steps for all users that need to submit jobs to the virtual cluster.

